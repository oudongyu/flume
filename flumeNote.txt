1. Flume介绍
1.1. 什么是Flume
flume 作为 cloudera 开发的实时日志收集系统，受到了业界的认可与广泛应用。Flume 初始的发行版本目前被统称为 Flume OG（original generation），属于 cloudera。但随着 FLume 功能的扩展，Flume OG 代码工程臃肿、核心组件设计不合理、核心配置不标准等缺点暴露出来，尤其是在 Flume OG 的最后一个发行版本 0.94.0 中，日志传输不稳定的现象尤为严重，为了解决这些问题，2011 年 10 月 22 号，cloudera 完成了 Flume-728，对 Flume 进行了里程碑式的改动：重构核心组件、核心配置以及代码架构，重构后的版本统称为 Flume NG（next generation）；改动的另一原因是将 Flume 纳入 apache 旗下，cloudera Flume 改名为 Apache Flume。 
1.1.1. Flume的特点
flume是一个分布式、可靠、和高可用的海量日志采集、聚合和传输的系统。支持在日志系统中定制各类数据发送方，用于收集数据;同时，Flume提供对数据进行简单处理，并写到各种数据接受方(比如文本、HDFS、Hbase等)的能力。

flume的数据流由事件(Event)贯穿始终。事件是Flume的基本数据单位，它携带日志数据(字节数组形式)并且携带有头信息，这些Event由Agent外部的Source生成，当Source捕获事件后会进行特定的格式化，然后Source会把事件推入(单个或多个)Channel中。你可以把Channel看作是一个缓冲区，它将保存事件直到Sink处理完该事件。Sink负责持久化日志或者把事件推向另一个Source。
1.1.2. Flume的可靠性
当节点出现故障时，日志能够被传送到其他节点上而不会丢失。Flume提供了三种级别的可靠性保障，从强到弱依次分别为：end-to-end（收到数据agent首先将event写到磁盘上，当数据传送成功后，再删除；如果数据发送失败，可以重新发送。），Store on failure（这也是scribe采用的策略，当数据接收方crash时，将数据写到本地，待恢复后，继续发送），Besteffort（数据发送到接收方后，不会进行确认）。
1.1.3. Flume的可恢复性
还是靠Channel。推荐使用FileChannel，事件持久化在本地文件系统里(性能较差)。
1.2. Flume基本概念
Agent	一个Agent包含 source ，channel，sink 和其他组件。
Source	Source 负责接收event或通过特殊机制产生event，并将events批量的放到一个或多个Channel
Channel	Channel位于Source和Sink之间，用于缓存进来的event
Sink	Sink负责将event传输到下一个source或最终目的地，成功后将event从channel移除
Client	Client 是一个将原始log包装成events并且发送他们到一个或多个agent的实体，目的是从数据源系统中解耦Flume，在flume的拓扑结构中不是必须的。
Events	Event是Flume数据传输的基本单元。可以是日志记录、 avro 对象等。
1.3. Flume三大组件
Flume主要由3个重要的组件购成：
Source:
Source:完成对日志数据的收集，分成transtion 和 event 打入到channel之中。
Sink:取出Channel中的数据，进行相应的存储文件系统，数据库，或者提交到远程服务器。
Channel:主要提供一个队列的功能，对source提供中的数据进行简单的缓存。
1.3.1. Source
1.3.2. Sink

1.3.3. Channel缓存池

2. 安装配置
2.1. 解压安装
tar -zxvf apache-flume-1.7.0-bin.tar.gz -C /opt/
2.2. 配置环境变量
vi /etc/profile
export FLUME_HOME=/opt/flume-1.7.0
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$FLUME_HOME/bin:
保存退出后，刷新profile
source /etc/profile
2.3. 验证
#查看flume版本：
[root@opt bin]# flume-ng version
Flume 1.7.0
Source code repository: https://git-wip-us.apache.org/repos/asf/flume.git
Revision: 511d868555dd4d16e6ce4fedc72c2d1454546707
Compiled by bessbd on Wed Oct 12 20:51:10 CEST 2016
From source with checksum 0d21b3ffdc55a07e1d08875872c00523
#出现上面的信息，表示安装成功了
3. 实时采集案例
3.1. Spool+memory+hdfs
创建配置文件a1.conf:
a1.sources = r1
a1.channels = c1
a1.sinks = k1
a1.sources.r1.type = spooldir
a1.sources.r1.spoolDir = /opt/flume-1.7.0/flumeTest/spoolDir
a1.sources.r1.fileHeader = true
a1.channels.c1.type = memory
a1.channels.c1.capacity = 10000
a1.channels.c1.transactionCapacity = 10000
a1.sinks.k1.type = hdfs
a1.sinks.k1.hdfs.path = hdfs://houda01:9000/flume/events/%y-%m-%d_%H
a1.sinks.k1.hdfs.filePrefix = events-
a1.sinks.k1.hdfs.useLocalTimeStamp=true
a1.sinks.k1.hdfs.fileType=DataStream
#不按照条数生成文件
a1.sinks.k1.hdfs.rollCount = 0
#HDFS上的文件达到1M时生成一个文件
a1.sinks.k1.hdfs.rollSize = 1048576
#HDFS上的文件达到60秒生成一个文件
a1.sinks.k1.hdfs.rollInterval = 60
#指定上传文件的副本数
#a1.sinks.k1.hdfs.minBlockReplicas=1
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1

执行agent:
flume-ng agent -n a1 -c /opt/flume-1.7.0/conf/ -f /opt/flume-1.7.0/flumeTest/spool-hdfs.conf -Dflume.root.logger=INFO,console
3.2. Exec+memory+logger
创建配置文件a2.conf：
#定义agent名， source、channel、sink的名称
a2.sources = r1
a2.channels = c1
a2.sinks = k1
1.#具体定义source
2.a2.sources.r1.type = exec
3.a2.sources.r1.command = tail -f /opt/testdata/flume/logs/0.log
4.
5.#具体定义channel
6.a2.channels.c1.type = memory
7.a2.channels.c1.capacity = 1000
8.a2.channels.c1.transactionCapacity = 100
9.
10.#具体定义sink
11.a2.sinks.k1.type = logger
12.
13.#组装source、channel、sink
14.a2.sources.r1.channels = c1
15.a2.sinks.k1.channel = c1
执行agent:
bin/flume-ng agent -n a2  conf -f /hadoop/testdata/flume/a2.conf -Dflume.root.logger=INFO,console
3.3 .两台机器之间发送日志
exec-memory-avro 到 avro-memory-logger
第一台机器的conf
16.a1.sources = r1
17.a1.channels = c1
18.a1.sinks = k1
19.a1.sources.r1.type = exec
20.a1.sources.r1.command = tail -F /opt/flume-1.7.0/flumeTest/0.log
21.
22.a1.channels.c1.type = memory
23.a1.channels.c1.capacity = 10000
24.a1.channels.c1.transactionCapacity = 10000
25.a1.sinks.k1.type = avro
26.a1.sinks.k1.hostname = 192.168.8.102
27.a1.sinks.k1.port = 4545
28.a1.sources.r1.channels = c1
第二台机器的conf
29.a1.sources = r1
30.a1.channels = c1
31.a1.sinks = k1
32.
33.a1.sources.r1.type = avro
34.a1.sources.r1.bind = 0.0.0.0
35.a1.sources.r1.port = 4545
36.
37.a1.channels.c1.type = memory
38.a1.channels.c1.capacity = 100
39.a1.channels.c1.transactionCapacity = 10
40.
41.a1.sinks.k1.type = logger
42.
43.a1.sources.r1.channels = c1
44.a1.sinks.k1.channel = c1

3.4 拦截器 
host拦截器使用
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# Describe/configure the source
a1.sources.r1.type = exec
a1.sources.r1.command = tail -F /flumeTest/log.0


a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = host
a1.sources.r1.interceptors.i1.useIP = false
a1.sources.r1.interceptors.i1.hostHeader = hostname


# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 1000

# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1

# Describe the sink
a1.sinks.k1.type = hdfs
a1.sinks.k1.channel = c1
a1.sinks.k1.hdfs.path = /flume/events/%{hostname}/%y-%m-%d/
a1.sinks.k1.hdfs.fileType = DataStream
a1.sinks.k1.hdfs.useLocalTimeStamp = true
a1.sinks.k1.hdfs.filePrefix = events-
#当文件大小为52428800字节时，将临时文件滚动成一个目标文件
a1.sinks.hdfsSink.hdfs.rollSize = 52428800
#events数据达到该数量的时候，将临时文件滚动成目标文件
a1.sinks.hdfsSink.hdfs.rollCount = 0
#每隔N s将临时文件滚动成一个目标文件
a1.sinks.hdfsSink.hdfs.rollInterval = 1200
#配置前缀和后缀
a1.sinks.hdfsSink.hdfs.filePrefix=run
a1.sinks.hdfsSink.hdfs.fileSuffix=.data

REGEX_FILTER拦截器
a1.sources = r1
a1.sinks = k1
a1.channels = c1

a1.sources.r1.type = exec
a1.sources.r1.command = tail -F /opt/flume-1.7.0/flumeTest/log.1
a1.sources.r1.interceptors=i4
a1.sources.r1.interceptors.i4.type=REGEX_FILTER

a1.sources.r1.interceptors.i4.regex=(error)|(warn)
#false 代表 只要符合条件的，true代表 只要匹配不到的结果
a1.sources.r1.interceptors.i4.excludeEvents=false

a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.sinks.k1.type = logger

a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1

静态拦截器和多source用法
第一台机器的conf：
# Name the components on this agent
a1.sources = r1 r2
a1.sinks = k1
a1.channels = c1
 
# Describe/configure the source
# 元数据类型
a1.sources.r1.type = exec
a1.sources.r1.command = tail -F /opt/flume-1.7.0/flumeTest/access.log
# 拦截器别名
a1.sources.r1.interceptors = i1
# 拦截器类型
a1.sources.r1.interceptors.i1.type = static
# 拦截的键值对
a1.sources.r1.interceptors.i1.key = type
a1.sources.r1.interceptors.i1.value = access
 
a1.sources.r2.type = exec
a1.sources.r2.command = tail -F /opt/flume-1.7.0/flumeTest/nginx.log
a1.sources.r2.interceptors = i2
a1.sources.r2.interceptors.i2.type = static
a1.sources.r2.interceptors.i2.key = type
a1.sources.r2.interceptors.i2.value = nginx
 
# 下沉的目的地
# Describe the sink
a1.sinks.k1.type = avro
a1.sinks.k1.hostname = houda02
a1.sinks.k1.port = 4545
 
# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 2000
a1.channels.c1.transactionCapacity = 1000
 
# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sources.r2.channels = c1
a1.sinks.k1.channel = c1

第二台机器的conf：
a1.sources = r1
a1.sinks = k1
a1.channels = c1
 
 
# 定义source
a1.sources.r1.type = avro
a1.sources.r1.bind = houda02
a1.sources.r1.port =4545
 
# 添加时间拦截器，将没有时间戳的event添加上时间戳
a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = org.apache.flume.interceptor.TimestampInterceptor$Builder
 
 
# 定义channels
a1.channels.c1.type = memory
a1.channels.c1.capacity = 20000
a1.channels.c1.transactionCapacity = 10000
 
# 定义sink
a1.sinks.k1.type = hdfs
a1.sinks.k1.hdfs.path=hdfs://houda01:9000/source/logs/%{type}/%Y%m%d
a1.sinks.k1.hdfs.filePrefix =events
a1.sinks.k1.hdfs.fileType = DataStream
a1.sinks.k1.hdfs.writeFormat = Text
# 生成的文件不按条数生成
a1.sinks.k1.hdfs.rollCount = 0
# 生成的文件不按时间生成
a1.sinks.k1.hdfs.rollInterval = 30
# 生成的文件按大小生成
a1.sinks.k1.hdfs.rollSize  = 10485760
#a1.sinks.k1.hdfs.rollSize  =0
# 批量写入hdfs的个数
a1.sinks.k1.hdfs.batchSize = 20
# flume操作hdfs的线程数（包括新建，写入等）
a1.sinks.k1.hdfs.threadsPoolSize=10
# 操作hdfs超时时间
a1.sinks.k1.hdfs.callTimeout=30000
 
# 组装source、channel、sink
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1


